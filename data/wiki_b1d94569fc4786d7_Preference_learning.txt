Title: Preference learning
URL: https://en.wikipedia.org/wiki/Preference_learning
PageID: 34072838
Categories: Category:Information retrieval techniques, Category:Machine learning
Source: Wikipedia (CC BY-SA 4.0).

-----
Preference learning is a subfield of machine learning that focuses on modeling and predicting preferences based on observed preference information. [ 1 ] Preference learning typically involves supervised learning using datasets of pairwise preference comparisons, rankings, or other preference information.
Tasks
The main task in preference learning concerns problems in " learning to rank ". According to different types of preference information observed, the tasks are categorized as three main problems in the book Preference Learning : [ 2 ]
Label ranking
In label ranking, the model has an instance space X = { x i } {\displaystyle X=\{x_{i}\}\,\!} and a finite set of labels Y = { y i | i = 1 , 2 , ⋯ , k } {\displaystyle Y=\{y_{i}|i=1,2,\cdots ,k\}\,\!} . The preference information is given in the form y i ≻ x y j {\displaystyle y_{i}\succ _{x}y_{j}\,\!} indicating instance x {\displaystyle x\,\!} shows preference in y i {\displaystyle y_{i}\,\!} rather than y j {\displaystyle y_{j}\,\!} . A set of preference information is used as training data in the model. The task of this model is to find a preference ranking among the labels for any instance.
It was observed that some conventional classification problems can be generalized in the framework of label ranking problem: [ 3 ] if a training instance x {\displaystyle x\,\!} is labeled as class y i {\displaystyle y_{i}\,\!} , it implies that ∀ j ≠ i , y i ≻ x y j {\displaystyle \forall j\neq i,y_{i}\succ _{x}y_{j}\,\!} . In the multi-label case, x {\displaystyle x\,\!} is associated with a set of labels L ⊆ Y {\displaystyle L\subseteq Y\,\!} and thus the model can extract a set of preference information { y i ≻ x y j | y i ∈ L , y j ∈ Y ∖ L } {\displaystyle \{y_{i}\succ _{x}y_{j}|y_{i}\in L,y_{j}\in Y\backslash L\}\,\!} . Training a preference model on this preference information and the classification result of an instance is just the corresponding top ranking label.
Instance ranking
Instance ranking also has the instance space X {\displaystyle X\,\!} and label set Y {\displaystyle Y\,\!} . In this task, labels are defined to have a fixed order y 1 ≻ y 2 ≻ ⋯ ≻ y k {\displaystyle y_{1}\succ y_{2}\succ \cdots \succ y_{k}\,\!} and each instance x l {\displaystyle x_{l}\,\!} is associated with a label y l {\displaystyle y_{l}\,\!} . Giving a set of instances as training data, the goal of this task is to find the ranking order for a new set of instances.
Object ranking
Object ranking is similar to instance ranking except that no labels are associated with instances. Given a set of pairwise preference information in the form x i ≻ x j {\displaystyle x_{i}\succ x_{j}\,\!} and the model should find out a ranking order among instances.
Techniques
There are two practical representations of the preference information A ≻ B {\displaystyle A\succ B\,\!} . One is assigning A {\displaystyle A\,\!} and B {\displaystyle B\,\!} with two real numbers a {\displaystyle a\,\!} and b {\displaystyle b\,\!} respectively such that a > b {\displaystyle a>b\,\!} . Another one is assigning a binary value V ( A , B ) ∈ { 0 , 1 } {\displaystyle V(A,B)\in \{0,1\}\,\!} for all pairs ( A , B ) {\displaystyle (A,B)\,\!} denoting whether A ≻ B {\displaystyle A\succ B\,\!} or B ≻ A {\displaystyle B\succ A\,\!} . Corresponding to these two different representations, there are two different techniques applied to the learning process.
Utility function
If we can find a mapping from data to real numbers, ranking the data can be solved by ranking the real numbers. This mapping is called utility function . For label ranking the mapping is a function f : X × Y → R {\displaystyle f:X\times Y\rightarrow \mathbb {R} \,\!} such that y i ≻ x y j ⇒ f ( x , y i ) > f ( x , y j ) {\displaystyle y_{i}\succ _{x}y_{j}\Rightarrow f(x,y_{i})>f(x,y_{j})\,\!} . For instance ranking and object ranking, the mapping is a function f : X → R {\displaystyle f:X\rightarrow \mathbb {R} \,\!} .
Finding the utility function is a regression learning problem [ citation needed ] which is well developed in machine learning.
Preference relations
The binary representation of preference information is called preference relation. For each pair of alternatives (instances or labels), a binary predicate can be learned by conventional supervised learning approach. Fürnkranz and Hüllermeier proposed this approach in label ranking problem. [ 4 ] For object ranking, there is an early approach by Cohen et al. [ 5 ]
Using preference relations to predict the ranking will not be so intuitive. Since observed preference relations may not always be transitive due to inconsistencies in the data, finding a ranking that satisfies all the preference relations may not be possible or may result in multiple possible solutions. A more common approach is to find a ranking solution which is maximally consistent with the preference relations. This approach is a natural extension of pairwise classification. [ 4 ]
Uses
Preference learning can be used in ranking search results according to feedback of user preference. Given a query and a set of documents, a learning model is used to find the ranking of documents corresponding to the relevance with this query. More discussions on research in this field can be found in Tie-Yan Liu 's survey paper. [ 6 ]
Another application of preference learning is recommender systems . [ 7 ] Online store may analyze customer's purchase record to learn a preference model and then recommend similar products to customers. Internet content providers can make use of user's ratings to provide more user preferred contents.
References
